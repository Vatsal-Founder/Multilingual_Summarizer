# Multilingual Summarizer â€” mT5 (Hindi â€¢ English â€¢ French)

An endâ€‘toâ€‘end **MLOps** project that fineâ€‘tunes **`csebuetnlp/mT5_multilingual_XLSum`** for multilingual abstractive summarization and serves a **Flask** app where users paste an article in **Hindi, English, or French** and receive a concise summary.

> Repo: `Vatsal-Founder/Multilingual_Summarizer` â€” modular codebase with configs, pipelines, and CI workflows.
> Base model: mT5 fineâ€‘tuned on **XLâ€‘Sum** (45 languages).

---

## Highlights

* ğŸŒ **Multilingual input**: Hindi, English, and French (extensible to other XLâ€‘Sum languages).
* ğŸ§  **Fineâ€‘tuned mT5**: starts from `csebuetnlp/mT5_multilingual_XLSum` and adapts to your settings.
* ğŸ§± **Modular pipelines**: ingestion â†’ preprocessing â†’ training â†’ evaluation â†’ packaging.
* ğŸš€ **Serve with Flask**: paste text â†’ get summary; simple HTML templates included.
* ğŸ” **Reproducible runs**: configâ€‘driven via YAML; logs and artifacts saved per run.
* ğŸ”„ **Workflows**: GitHub Actions for CI (lint/test/build) and optional containerization.

---

## Architecture

```
Raw text/article â”€â”€â–º Ingestion â”€â”€â–º Preprocess (clean, tokenize) â”€â”€â–º Fineâ€‘tune mT5
                                                     â”‚
                                                     â”œâ”€â”€â–º Evaluate (ROUGE, length)
                                                     â”‚
                                                     â””â”€â”€â–º Package model + tokenizer â”€â”€â–º Flask API/UI
                                                                                         â”‚
                                                                                         â–¼
                                                                                    Summary output
```

---

## Project structure

```
.
â”œâ”€â”€ .github/workflows/        # CI pipelines
â”œâ”€â”€ config/                   # config.yaml and stage configs
â”œâ”€â”€ logs/                     # training/inference logs
â”œâ”€â”€ research/                 # notebooks / experiments
â”œâ”€â”€ src/                      # package: components & pipelines
â”œâ”€â”€ templates/                # Flask HTML templates
â”œâ”€â”€ app.py                    # Flask app (serve summaries)
â”œâ”€â”€ main.py                   # pipeline runner / orchestrator
â”œâ”€â”€ params.yaml               # hyperparams & run settings
â”œâ”€â”€ Dockerfile                # container image (optional)
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # this file
```

---

## Moduleâ€‘byâ€‘module

**1) Data Ingestion**

* Accepts pasted text or dataset samples; optional language tag (hi/en/fr).

**2) Preprocessing / Transformation**

* Cleans HTML/whitespace, normalizes punctuation, truncates to max length, and prepares input/output pairs for seq2seq fineâ€‘tuning.

**3) Model Trainer**

* Loads tokenizer + `AutoModelForSeq2SeqLM` from `csebuetnlp/mT5_multilingual_XLSum`.
* Trains with params from `params.yaml` (batch size, lr, epochs, max\_length, beam size, etc.).

**4) Evaluation**

* Computes ROUGEâ€‘1/2/L and length metrics per language; logs perâ€‘run scores.

**5) Packaging / Registry**

* Saves the fineâ€‘tuned weights, tokenizer, and a `config.json` for the Flask app to consume.

**6) Serving (`app.py`)**

* Flask endpoint renders a form where you select a language (Hindi/English/French) and paste content.
* Returns a concise abstractive summary.

---

## Quick Start

### 1) Setup

```bash
git clone https://github.com/Vatsal-Founder/Multilingual_Summarizer.git
cd Multilingual_Summarizer
python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2) Configure

Edit **`config/config.yaml`** and **`params.yaml`** to set model paths and hyperparameters (train/val splits, max lengths, learning rate, batch size, epochs). If you use a remote tracker, export its URI/envs.

### 3) Train / Fineâ€‘tune

```bash
# endâ€‘toâ€‘end pipeline
python main.py

# or run by stage (examples)
python main.py --stage ingest
python main.py --stage transform
python main.py --stage train
python main.py --stage evaluate
```

Artifacts (model + tokenizer) are saved to the configured `artifacts/` path.

### 4) Run the Flask app

```bash
python app.py
```

Visit **[http://localhost:5000](http://localhost:5000)**. Paste an article (Hindi/English/French) and click **Summarize**.

---

## Configuration reference (minimal)

```yaml
# params.yaml (illustrative)
model_name: csebuetnlp/mT5_multilingual_XLSum
max_input_length: 2048
max_target_length: 128
batch_size: 4
learning_rate: 3e-5
epochs: 3
beam_size: 4
lang_supported: [hi, en, fr]
```

---

## Docker (optional)

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["python", "app.py"]
```

Build & run:

```bash
docker build -t multilingual-summarizer .
docker run -p 5000:5000 multilingual-summarizer
```

---

## Notes

* Base model **mT5â€‘multilingualâ€‘XLSum** is trained on **XLâ€‘Sum** (45 languages); this app focuses on **Hindi/English/French**, but you can enable more by updating `lang_supported` and tokenizer settings.
* For long inputs, the app uses chunking/length limits from `params.yaml` to keep inference stable.

---

## License

GPLâ€‘3.0 Â© Vatsal Founder
